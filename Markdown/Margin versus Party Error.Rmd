---
title: "Margin Versus Party Error"
author: "Haley Reed"
date: "7/3/2020"
output: html_document
bibliography: electionworkingbib.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, error=FALSE, warning=FALSE)
knitr::opts_knit$set(root.dir = dirname(getwd()))
library(sjPlot)
library(sjmisc)
library(sjlabelled)

#This Markdown Script calls "Exploration of Margin v. Party Error.r" and "ANOVA model just pollsters indirectly by calling their saved csv files. 
```


**Introduction**

In looking at past polls and elections, the "bias" of a poll is defined around the margin of difference between the two primary candidates of a race. 

What is the relationship between that "bias" and the actual number of percentage points a particular poll is off in judging candidates in a vacuum? 

What is the relationship between Republican Error, Democratic error, and traditional bias with the following definitions?

$$DemocraticError = DemocraticCanditatePollingPercent-DemocraticActualPercentage$$

$$RepublicanError = RepublicanCanditatePollingPercent-RepublicanActualPercentage$$

$$Bias = MarginPoll - MarginActual$$

$$MarginPoll = DemocraticCanditatePollingPercent-RepublicanCanditatePollingPercent$$
$$MarginActual = DemocraticActualPercentage-RepublicanActualPercentage$$

**Fisherian Exploration**

Before we get into Bayesian modeling it worth doing some inital exploration with Fisherian statistics...

```{r}
mydata=read.csv("Data/raw-polls_538_cleaned.csv")
#is year rep. lean = -(dem. year lean) ?
minPolls=30
myDataMyPollsters=  mydata[0,]
for(myPollster in unique(mydata$pollster))
{
  
  #subset to a dataset with just each pollster
  subpoll=subset(mydata, pollster==myPollster)
  
  #if that subset has more than thirty entries, use it:
  if(nrow(subpoll)>minPolls){
    #combine each of these subsets together
    myDataMyPollsters=rbind(myDataMyPollsters, subpoll)
  }
}
myDataFrame = myDataMyPollsters
myDataFrame$pollster = factor( myDataFrame$pollster)
bestfit=lm(formula =  myDataFrame$repBias ~ myDataFrame$demBias)
plot(myDataFrame$demBias, myDataFrame$repBias, ylab="Republican Error", xlab="Democratic Error", main="Errors Dependent on each other, Matched By Poll")
abline(bestfit)
corrval=cor(myDataFrame$repBias, myDataFrame$demBias)
corrval1=cor(myDataFrame$demBias, myDataFrame$bias)
corrval2=cor(myDataFrame$repBias, myDataFrame$bias)

plot(myDataFrame$demBias, myDataFrame$bias, xlab="Democratic Error", ylab="Marginal Bias",main="Maginal Bias Plotted Dependent on Party Error")
bestfit2=lm(myDataFrame$bias~myDataFrame$demBias)
abline(bestfit2)

```


The summaries of these best fit lines of regression are shown below:


```{r, include=FALSE}
tab_model(bestfit,bestfit2, file="Simulations/output.html")

```




```{r}
htmltools::includeHTML("Simulations/output.html")

```

<br>

With a correlation value of `r corrval` between Democratic error and Republican error, we can see that the two are moderately correlated.

However, there is a higher correlation between party errors and bias measured in the traditional marginal sense is stronger. The correlation between democratic error and bias is `r corrval1`. And the correlation between republican error and bias is `r corrval2`. 

A great deal of the values for party error are negative because of the number of undecided voters polled. What is the impact of undecided voters for party error and marginal bias? We can explore these relationships with the plots below. 

```{r, Undecided Voter Relationships}
# Find out how many undecided voters there are in each poll
Undecided = 100 - myDataFrame$cand1_pct - myDataFrame$cand2_pct
myDataFrame$Undecided = Undecided
# What is the relationship between demBias and undecided Voters?
demUndecidedRelationship = lm( demBias ~ Undecided, data=myDataFrame)

# What is the relationship between repBias and undecided voters?
repUndecidedRelationship = lm( repBias ~ Undecided, data=myDataFrame)


plot(myDataFrame$Undecided,myDataFrame$demBias, xlab="Percent of Undecided Voters", ylab="Democratic Error")
abline(demUndecidedRelationship)
plot(myDataFrame$Undecided,myDataFrame$repBias,xlab="Percent of Undecided Voters", ylab="Republican Error")
abline(repUndecidedRelationship)
#stronger relationship between Republican bias and Undecided voters
plot(myDataFrame$Undecided,myDataFrame$bias,xlab="Percent of Undecided Voters", ylab="Marginal Bias")
marginUndecidedRelationship = lm( bias ~ Undecided, data=myDataFrame)

abline(marginUndecidedRelationship)
#In general, the more undecided voters, the more polls underestimate the power of republicans.
```


The lines of best fit plotted above are given by simple linear models with Republican Error, Democratic Error, and Marginal Bias as the response variables with percent of undecided voters in any poll acting as the explanatory variable. The coefficients and R squared values for each  model can be seen in the table below:

```{r}
tab_model(repUndecidedRelationship,demUndecidedRelationship,marginUndecidedRelationship)

```

<br>

From this table, we can see that in general, there is a stronger relationship between republican error and undecided voters than democratic error and undecided voters. And it appears that the more undecided voters, the more polls underestimate the power of the republican candidate. This can be seen clearly with the confidence intervals from the above table:

* The entire republican error confidence interval for the slope coefficient (-.40 to -.34) is less than the entire democratic error confidence interval for the slope coefficient (-19 to. -.12). Meaning that as the percent of undecided voters increases, the polls will underestimate the Republican candidate's vote share more dramatically than they will underestimate the Democratic candidate's vote share. 

* The entire confidence interval for marginal bias is above 0 (.16 to .27), meaning as the percent of undecided voters increase, the marginal bias will increase its tendency to overestimate the Democratic party's candidate. 


**Bayesian Modeling - Year Leans**

Now that we have done some brief exploration using Fisherian statistics, we can take a look at the data with Bayesian techniques. 

```{r, include=FALSE, fig.show='hide'}
#source(here::here('RScripts', 'Exploration of Margin v. Party Error.r'))
```

Summary info from Bayesian analysis for Democratic and Republican year leans are shown below for comparison. As well as these summary points for year leans plotted together...

```{r}
dtD=read.csv("Simulations/dtD.csv")
knitr::kable(dtD)

dtR=read.csv("Simulations/dtR.csv")
knitr::kable(dtR)
```

As discussed earlier, most of the party error values will be negative because of the effect of undecided voters. 

This denies the intuitive expectation that $DemocraticError = -RebuplicanError$. So what is the relationship between party errors during the years? The graphs below help us begin to understand.

```{r}
yearLabels=c("2000","2004","2008","2012","2016")
plot(dtD$yearLabels,dtD$Mode, col="blue", main="Year Leans", xlab="Election Year", 
     ylab="Most Credible Error Value", ylim=c(-5, 1) , xlim=c(1996, 2020), xaxt = "n"
     )
# Define the position of tick marks
axis(side = 1, 
     at = yearLabels, 
     labels = yearLabels,
     tck=-.05)
points(dtR$yearLabels, dtR$Mode, col="red")
# Add a legend
legend(1996, 1, legend=c("Democratic Error", "Republican Error"),
       col=c("blue", "red"), lty=1:2, cex=0.8)

plot(dtD$Mode,dtR$Mode, main="Democratic Versus Rebulican Year Leans, 2000-2016", xlab="Democratic Year Lean", 
     ylab="Republican Year Lean")
RelationshipBetween = lm(dtR$Mode~dtD$Mode)

abline(RelationshipBetween)
bestfit=lm(formula =  myDataFrame$demBias ~ myDataFrame$repBias)
abline(bestfit, col="red")
legend(-2.3, 0, legend=c("Best Fit for Bayesian Year Leans", "Best Fit for Fisherian Polls"), col=c("black", "red"), lty=1:2, cex=0.8)
```

```{r, include=FALSE}
tab_model(RelationshipBetween, file="Simulations/output1.html")
```

As demonstrated with the graph above, the Bayesian model modes of year leans overall do match similar expectations as described by the traditional linear model output. 


The simple linear model line of best fit for the Bayesian modes can be described by the coefficents below:

```{r}
htmltools::includeHTML("Simulations/output1.html")
```

<br>

**Bayesian Modeling - Pollster Error**

To answer the question if democratic pollster error is equal to republican pollster error, we can plot the most credible values for party error for each pollster against each other.


```{r}
#uses data from "ANOVA model -just pollsters.R"
demBiasPollsterSummary=read.csv("Simulations/demBiasPollsterSummary.csv")
repBiasPollsterSummary=read.csv("Simulations/repBiasPollsterSummary.csv")


plot(demBiasPollsterSummary$x,repBiasPollsterSummary$x, main="Democratic Versus Rebulican Pollster Errors, 2000-2016", xlab="Democratic Pollster Error", 
     ylab="Republican Pollster Error")
bestfitPollster=lm(repBiasPollsterSummary$x~demBiasPollsterSummary$x)
#tab_model(bestfitPollster)
bestfit=lm(formula =  myDataFrame$repBias ~ myDataFrame$demBias)
abline(bestfitPollster)
abline(bestfit, col="red")
legend(-8, 2, legend=c("Best Fit for Bayesian Pollster Errors", "Best Fit for Fisherian Polls"), col=c("black", "red"), lty=1:2, cex=0.8)
```

```{r, include=FALSE}
tab_model(bestfitPollster, file="Simulations/output2.html")
```


```{r}
 
htmltools::includeHTML("Simulations/output2.html")

```

<br>

As demonstrated by the plot, there is an evident relationship, but the relationship seems to differ from the negative best fit slope established earlier. 

**Bayesian Modeling - Democratic and Republican Error Dependent on Each Other**

We can also do direct Bayesian analysis between Democratic and Republican pollster error. 

The diagnostic plots all look good, take a look at the slope diagnostic visuals for example:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-Diagbeta1.png)

<br>

The post predictive plot for such analysis is shown below:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-PostPred.png)

And the posterior distributions of the parameters (as modeled with a t-distrubtion) can be seen below:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-PostMarg.png)

There are a couple key takeaways here:

* The entire highest density interval for the slope parameter is entirely below zero. We can say with confidence that when democratic error increases, republican error decreases (and vice-versa). 

* The entire highest density interval for the y-intercept is below zero. Contextually, meaning that when there is no democratic bias, we would expect polls to underestimate pollsters between 2.94% and 3.28%. 


**Bayesian Modeling - Democratic Error and Marginal Bias**

We can do similar exploration between democratic error and marginal bias. 

The diagnostic plots also look good here, take a look at the slope diagnostic visuals for example:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-MarginDiagbeta1.png)
<br>

The post predictive plot for such analysis is shown below:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-MarginPostPred.png)

And the posterior distributions of the parameters (as modeled with a t-distrubtion) can be seen below:

<br>

![](Figures/DoubleOneMetric-ErrorandBias-Jags-MarginPostMarg.png)

As we would expect, as the democratic error increases, so does the measure of the marginal democratic bias in polling. However, the marginal bias grows quicker than democratic error. The highest density interval estimates that for every 1% increase in democratic error, an increase in 1.5% to 1.59% in marginal bias should be expected. 


**Bayesian Modeling - Republican Error and Undecided Voters**

Since undecided voters seemed to have such an impact for Republican voters under traditional statistical analysis, we will return to that question with Bayesian methods. 

We can use the percent of undecided voters as the metric x-variable and the percent of Republican error as the metric y-variable. 

This satisfies the condition for a converging MCMC. The diagnostic plot for the slope coefficient is included below for reference:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-UndecidedDiagbeta1.png)
The post predictive plot for the analysis looks like:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-UndecidedPostPredYint.png)

And the distributions, along with their modes, and HDIs for each of the parameters of interest are included below:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-UndecidedPostMarg.png)
If you remember the traditional analysis that we began with, the modes for the intercepts are very similar to the estimates produced by the simple linear model. This consistency increases our confidence that the more undecided voters, the more polls underestimate the power of the republican candidate. 

**Conclusion**

The relationships between Republican Error, Democratic error, and traditional bias are not as simple as we might initially think. 

The relationship between the two party errors appears to be moderate, while the relationship between either party error and marginal bias is stronger.

What are some reasons for this?

* Undecided Voters 
* Non Response Bias
* Lack of Elastic Voters 

So how can we seek to understand bias better?

These relationships are not perfect, so it takes more work to properly interpret bias. It is important to have clear definitions, as established at the beginning of this exploration. Additionally, understanding undecided vote share may be necessary to understanding discrepancies between polled party vote share and actual party vote share. 

\newpage

**Works Cited**

---
#.bib for bib refrence
nocite: |
  @538rawpolldata
  @KrusckeTextbook
---