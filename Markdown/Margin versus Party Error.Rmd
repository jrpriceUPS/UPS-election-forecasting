---
title: "Margin Versus Party Error"
author: "Haley Reed"
date: "7/3/2020"
output: html_document
bibliography: electionworkingbib.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, error=FALSE, warning=FALSE)
knitr::opts_knit$set(root.dir = dirname(getwd()))
library(sjPlot)
library(sjmisc)
library(sjlabelled)

#This Markdown Script calls "Exploration of Margin v. Party Error.r" and "ANOVA model just pollsters indirectly by calling their saved csv files. 
```


**Introduction**

In looking at past polls and elections, the "bias" of a poll is defined around the margin of difference between the two primary candidates of a race. 

What is the relationship between that "bias" and the actual number of percentage points a particular poll is off in judging candidates in a vacuum? 

What is the relationship between Republican Error, Democratic error, and traditional bias with the following definitions?

$$DemocraticError = DemocraticCanditatePollingPercent-DemocraticActualPercentage$$

$$RepublicanError = RepublicanCanditatePollingPercent-RepublicanActualPercentage$$

$$Bias = MarginPoll - MarginActual$$

$$MarginPoll = DemocraticCanditatePollingPercent-RepublicanCanditatePollingPercent$$
$$MarginActual = DemocraticActualPercentage-RepublicanActualPercentage$$

**Fisherian Exploration**

Before we get into Bayesian modeling it worth doing some inital exploration with Fisherian statistics...

```{r}
mydata=read.csv("Data/raw-polls_538_cleaned.csv")
#is year rep. lean = -(dem. year lean) ?
minPolls=30
myDataMyPollsters=  mydata[0,]
for(myPollster in unique(mydata$pollster))
{
  
  #subset to a dataset with just each pollster
  subpoll=subset(mydata, pollster==myPollster)
  
  #if that subset has more than thirty entries, use it:
  if(nrow(subpoll)>minPolls){
    #combine each of these subsets together
    myDataMyPollsters=rbind(myDataMyPollsters, subpoll)
  }
}
myDataFrame = myDataMyPollsters
myDataFrame$pollster = factor( myDataFrame$pollster)
bestfit=lm(formula =  myDataFrame$repBias ~ myDataFrame$demBias)
plot(myDataFrame$demBias, myDataFrame$repBias, ylab="Republican Error", xlab="Democratic Error", main="Errors Dependent on each other, Matched By Poll")
abline(bestfit)
corrval=cor(myDataFrame$repBias, myDataFrame$demBias)
corrval1=cor(myDataFrame$demBias, myDataFrame$bias)
corrval2=cor(myDataFrame$repBias, myDataFrame$bias)

plot(myDataFrame$demBias, myDataFrame$bias, xlab="Democratic Error", ylab="Marginal Bias",main="Maginal Bias Plotted Dependent on Party Error")
bestfit2=lm(myDataFrame$bias~myDataFrame$demBias)
abline(bestfit2)

```


The summaries of these best fit lines of regression are shown below:


```{r, include=FALSE}
tab_model(bestfit,bestfit2, file="Simulations/output.html")

```




```{r}
htmltools::includeHTML("Simulations/output.html")

```

<br>

With a correlation value of `r corrval` between Democratic error and Republican error, we can see that the two are moderately correlated.

However, there is a higher correlation between party errors and bias measured in the traditional marginal sense is stronger. The correlation between democratic error and bias is `r corrval1`. And the correlation between republican error and bias is `r corrval2`. 

A great deal of the values for party error are negative because of the number of undecided voters polled. What is the impact of undecided voters for party error and marginal bias? We can explore these relationships with the plots below. 

```{r, Undecided Voter Relationships}
# Find out how many undecided voters there are in each poll
Undecided = 100 - myDataFrame$cand1_pct - myDataFrame$cand2_pct
myDataFrame$Undecided = Undecided
# What is the relationship between demBias and undecided Voters?
demUndecidedRelationship = lm( demBias ~ Undecided, data=myDataFrame)

# What is the relationship between repBias and undecided voters?
repUndecidedRelationship = lm( repBias ~ Undecided, data=myDataFrame)


plot(myDataFrame$Undecided,myDataFrame$demBias, xlab="Percent of Undecided Voters", ylab="Democratic Error")
abline(demUndecidedRelationship)
plot(myDataFrame$Undecided,myDataFrame$repBias,xlab="Percent of Undecided Voters", ylab="Republican Error")
abline(repUndecidedRelationship)
#stronger relationship between Republican bias and Undecided voters
plot(myDataFrame$Undecided,myDataFrame$bias,xlab="Percent of Undecided Voters", ylab="Marginal Bias")
marginUndecidedRelationship = lm( bias ~ Undecided, data=myDataFrame)

abline(marginUndecidedRelationship)
#In general, the more undecided voters, the more polls underestimate the power of republicans.
```


The lines of best fit plotted above are given by simple linear models with Republican Error, Democratic Error, and Marginal Bias as the response variables with percent of undecided voters in any poll acting as the explanatory variable. The coefficients and R squared values for each  model can be seen in the table below:

```{r}
tab_model(repUndecidedRelationship,demUndecidedRelationship,marginUndecidedRelationship)

```

<br>

From this table, we can see that in general, there is a stronger relationship between republican error and undecided voters than democratic error and undecided voters. And it appears that the more undecided voters, the more polls underestimate the power of the republican candidate. This can be seen clearly with the confidence intervals from the above table:

* The entire republican error confidence interval for the slope coefficient (-.40 to -.34) is less than the entire democratic error confidence interval for the slope coefficient (-19 to. -.12). Meaning that as the percent of undecided voters increases, the polls will underestimate the Republican candidate's vote share more dramatically than they will underestimate the Democratic candidate's vote share. 

* The entire confidence interval for marginal bias is above 0 (.16 to .27), meaning as the percent of undecided voters increase, the marginal bias will increase its tendency to overestimate the Democratic party's candidate. 

<br>

**Bayesian Modeling - Democratic and Republican Error Dependent on Each Other**

Now that we have done some brief exploration using Fisherian statistics, we can take a look at the data with Bayesian techniques. 

We can do direct Bayesian analysis between Democratic and Republican pollster error. 

The diagnostic plots all look good, take a look at the slope diagnostic visuals for example:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-Diagbeta1.png)

<br>


The post predictive plot for such analysis is shown below:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-PostPred.png)

And the posterior distributions of the parameters (as modeled with a t-distrubtion) can be seen below:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-PostMarg.png)

There are a couple key takeaways here:

* The entire highest density interval for the slope parameter is entirely below zero. We can say with confidence that when democratic error increases, republican error decreases (and vice-versa). 

* The entire highest density interval for the y-intercept is below zero. Contextually, meaning that when there is no democratic bias, we would expect polls to underestimate pollsters between 2.94% and 3.28%. 


**Bayesian Modeling - Democratic Error and Marginal Bias**

We can do similar exploration between democratic error and marginal bias. 

The diagnostic plots also look good here, take a look at the slope diagnostic visuals for example:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-MarginDiagbeta1.png)
<br>

The post predictive plot for such analysis is shown below:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-MarginPostPred.png)

And the posterior distributions of the parameters (as modeled with a t-distribution) can be seen below:

<br>

![](Figures/DoubleOneMetric-ErrorandBias-Jags-MarginPostMarg.png)

As we would expect, as the democratic error increases, so does the measure of the marginal democratic bias in polling. However, the marginal bias grows quicker than democratic error. The highest density interval estimates that for every 1% increase in democratic error, an increase in 1.5% to 1.59% in marginal bias should be expected. 


**Bayesian Modeling - Republican Error and Undecided Voters**

Since undecided voters seemed to have such an impact for Republican voters under traditional statistical analysis, we will return to that question with Bayesian methods. 

We can use the percent of undecided voters as the metric x-variable and the percent of Republican error as the metric y-variable. 

This satisfies the condition for a converging MCMC. The diagnostic plot for the slope coefficient is included below for reference:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-UndecidedDiagbeta1.png)

The post predictive plot for the analysis looks like:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-UndecidedPostPredYint.png)

And the distributions, along with their modes, and HDIs for each of the parameters of interest are included below:

![](Figures/DoubleOneMetric-ErrorandBias-Jags-UndecidedPostMarg.png)

If you remember the traditional analysis that we began with, the modes for the intercepts are very similar to the estimates produced by the simple linear model. This consistency increases our confidence that the more undecided voters, the more polls underestimate the power of the republican candidate. 

**Bayesian Modeling - Year Leans**

Is the relationship between democratic error and republican error the same every year? How do the year leans vary year to year? Do they vary in a way that is predictable?

We can explore these questions with an ANCOVA-adjacent Bayesian model with a metric predictor of democratic error percentage, a nominal predictor of year, and metric response variable of republican error percentage.

Results from that Bayesian model can be summarized below, but first we must check for MCMC convergence!

![All conditions for converge are sufficiently meet as represented by the slope coefficent for 2000.](Figures/yearLean-partyBias-ANCOVA-DiagaMet[1].png)

Now we can look at posterior distributions:

![](Figures/yearLean-partyBias-ANCOVA-PostPred-2000.png) ![](Figures/yearLean-partyBias-ANCOVA-PostPred-2004.png) 
![](Figures/yearLean-partyBias-ANCOVA-PostPred-2008.png) ![](Figures/yearLean-partyBias-ANCOVA-PostPred-2012.png) 
![](Figures/yearLean-partyBias-ANCOVA-PostPred-2016.png)

While it is hard to see because of scaling, there are some differences between the years. To get a better idea, a table of the summary info is shown below:

```{r}
YearLeanSumm=read.csv("Simulations/YearLeanSumm.csv")
knitr::kable(YearLeanSumm)
```

Interestingly enough, none of the coefficient modes (y-intercept or slope) fall within the HDIs for slope and y-intercept established in the first Bayesian analysis that has no metric predictor.
 
 *(y-intercept HDI: -3.28 to -2.94)
 *(slope HDI: -.595 to .495)
 
This suggests that the relationship between republican error and democratic error varies from year to year. 

**Bayesian Modeling - Pollster Error**

To answer the question if democratic pollster error is equal to republican pollster error, we can plot the most credible values for party error for each pollster against each other.

An example of diagnostic visuals (for the y-intercept for the ABC News-The Washington Post pollster) are shown below:

![](Figures/pollsterError-ANCOVA-Diaga[1].png)

A few of the post predictive plots are also included below:

![](Figures/pollsterError-ANCOVA-PostPred-YouGov.png) ![](Figures/pollsterError-ANCOVA-PostPred-SrvyUSA.png)
![](Figures/pollsterError-ANCOVA-PostPred-Gallup.png) ![](Figures/pollsterError-ANCOVA-PostPred-QnnpcUn.png)

<br>

A full list of coefficients for all sampled pollsters is given below:

```{r}
PollsterSumm=read.csv("Simulations/PollsterSumm.csv")
knitr::kable(PollsterSumm)
```

Similar to year leans, while generally similar, the models for republican bias based on democratic bias vary by pollster. You can see statistical evidence for a difference between the pollsters Quinnipiac University and Rasmussen Reports-Pulse Opinion Research with an established Region of Practical Equivalence of -1 to 1. The entire HDI for the difference between these two pollster falls above the ROPE, indicating that the hypothesis that there is no difference in the true parameter values of these two pollsters is not credible. A plot showing the differnce between the two pollsters is shown below:

![](Figures/pollsterError-ANCOVA-RRp-POR.v.QnnpcUn.png)

**Conclusion**

The relationships between Republican Error, Democratic error, and traditional bias are not as simple as we might initially think. 

The relationship between the two party errors appears to be moderate, while the relationship between either party error and marginal bias is stronger.

What are some reasons for this?

* Undecided Voters 
* Non Response Bias
* Lack of Elastic Voters 

So how can we seek to understand bias better?

These relationships are not perfect, so it takes more work to properly interpret bias. It is important to have clear definitions, as established at the beginning of this exploration. Additionally, understanding undecided vote share may be necessary to understanding discrepancies between polled party vote share and actual party vote share. 

\newpage

**Works Cited**

---
#.bib for bib refrence
nocite: |
  @538rawpolldata
  @KrusckeTextbook
---